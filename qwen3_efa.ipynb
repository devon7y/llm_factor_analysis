{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Based Pseudo-Factor Analysis (Guenole et al. Methodology)\n",
    "\n",
    "**Psychometric scale validation using transformer embeddings and exploratory factor analysis**\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements the Pseudo-Factor Analysis (PFA) approach from Guenole et al. for validating psychological scales using pre-trained language model embeddings:\n",
    "\n",
    "### Key Steps:\n",
    "1. **Atomic-Reversed Encoding**: Apply item scoring direction (+1/-1) to embeddings\n",
    "2. **Cosine Similarity Matrix**: Treat normalized similarities as pseudo-correlations\n",
    "3. **Exploratory Factor Analysis**: ML extraction with oblique rotation\n",
    "4. **Psychometric Diagnostics**: DAAL, Tucker congruence, KMO/Bartlett tests\n",
    "\n",
    "### Methodological Choices (Guenole et al.):\n",
    "- **Extraction**: Maximum Likelihood (ML) - not principal components\n",
    "- **Rotation**: Oblique (Promax/Oblimin) to allow factor correlations\n",
    "- **Input**: Cosine similarity of atomic-reversed embeddings\n",
    "- **Validation**: DAAL, Tucker φ, KMO, Bartlett\n",
    "\n",
    "### References:\n",
    "- Guenole, N., et al. (2024). Pre-trained language models for psychometric validation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c3030",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Import all required libraries for PFA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768db4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import percentileofscore\n",
    "import scipy.stats as stats\n",
    "\n",
    "try:\n",
    "    from factor_analyzer import FactorAnalyzer\n",
    "    from factor_analyzer.utils import calculate_kmo, calculate_bartlett_sphericity\n",
    "    FACTOR_ANALYZER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"\\nWARNING: factor_analyzer not installed!\")\n",
    "    print(\"Install with: pip install factor-analyzer\")\n",
    "    print(\"Continuing with limited functionality...\\n\")\n",
    "    FACTOR_ANALYZER_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9960ae",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set all parameters for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce759b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MODEL SELECTION\n",
    "# ==============================================================================\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"Qwen/Qwen3-Embedding-4B\",\n",
    "]\n",
    "\n",
    "# ==============================================================================\n",
    "# PRE-GENERATED EMBEDDINGS\n",
    "# ==============================================================================\n",
    "\n",
    "USE_PREGENERATED = False\n",
    "PREGENERATED_EMBEDDINGS = {\n",
    "    \"4B\": \"embeddings/dass_items_4B.npz\",\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# SCALE DATA PATH\n",
    "# ==============================================================================\n",
    "# Expected CSV columns:\n",
    "#   - code: item identifier (e.g., \"DASS01\", \"E1\")\n",
    "#   - item: the text of the scale item\n",
    "#   - factor: theoretical factor label (e.g., \"Anxiety\", \"Extraversion\")\n",
    "#   - scoring: [OPTIONAL] +1 for normal items, -1 for reverse-scored items\n",
    "#\n",
    "# If 'scoring' column is missing, all items default to +1 with a warning.\n",
    "# ==============================================================================\n",
    "\n",
    "SCALE_CSV_PATH = 'scales/DASS_items.csv'\n",
    "\n",
    "# ==============================================================================\n",
    "# EFA SETTINGS\n",
    "# ==============================================================================\n",
    "\n",
    "N_FACTORS = None  # None = auto via parallel analysis, or set to integer (e.g., 3)\n",
    "ROTATION_METHOD = 'promax'  # 'promax', 'oblimin', or 'varimax'\n",
    "EIGEN_CRITERIA = 'parallel'  # 'parallel' (recommended) or 'eigen1'\n",
    "PARALLEL_ITER = 100\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ==============================================================================\n",
    "# ENSEMBLE ANALYSIS\n",
    "# ==============================================================================\n",
    "\n",
    "ENSEMBLE = False  # Set to True to average similarity matrices across models\n",
    "\n",
    "# ==============================================================================\n",
    "# EMPIRICAL LOADINGS (optional)\n",
    "# ==============================================================================\n",
    "\n",
    "EMPIRICAL_LOADINGS_PATH = None  # e.g., 'empirical_loadings.csv' or None\n",
    "\n",
    "# ==============================================================================\n",
    "# OUTPUT\n",
    "# ==============================================================================\n",
    "\n",
    "SAVE_DIR = 'results'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "# ==============================================================================\n",
    "# DISPLAY CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Scale: {SCALE_CSV_PATH}\")\n",
    "print(f\"Models: {[m.split('/')[-1] for m in MODEL_NAMES]}\")\n",
    "print(f\"Factors: {N_FACTORS or 'Auto'}\")\n",
    "print(f\"Rotation: {ROTATION_METHOD}\")\n",
    "print(f\"Retention: {EIGEN_CRITERIA}\")\n",
    "print(f\"Output: {SAVE_DIR}/\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7c86b",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Functions for atomic-reversed encoding, parallel analysis, DAAL, and Tucker congruence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27858423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_atomic_reversed(embeddings, scoring):\n",
    "    \"\"\"Apply atomic-reversed encoding (Guenole et al.)\"\"\"\n",
    "    scoring_array = np.array(scoring).reshape(-1, 1)\n",
    "    embeddings_signed = embeddings * scoring_array\n",
    "    norms = np.linalg.norm(embeddings_signed, axis=1)\n",
    "    zero_norm_items = np.where(norms == 0)[0]\n",
    "    if len(zero_norm_items) > 0:\n",
    "        print(f\"  WARNING: {len(zero_norm_items)} items have zero norm after signing\")\n",
    "        for idx in zero_norm_items:\n",
    "            embeddings_signed[idx] = embeddings[idx]\n",
    "    embeddings_normalized = embeddings_signed / np.linalg.norm(embeddings_signed, axis=1, keepdims=True)\n",
    "    return embeddings_normalized\n",
    "\n",
    "def compute_parallel_analysis(corr_matrix, n_iter=100, percentile=95, random_state=42):\n",
    "    \"\"\"Parallel analysis for factor retention\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_items = corr_matrix.shape[0]\n",
    "    obs_eigenvalues = np.linalg.eigvalsh(corr_matrix)\n",
    "    obs_eigenvalues = np.sort(obs_eigenvalues)[::-1]\n",
    "    random_eigenvalues = []\n",
    "    for _ in range(n_iter):\n",
    "        random_data = np.random.randn(n_items, n_items)\n",
    "        random_corr = np.corrcoef(random_data)\n",
    "        eigs = np.linalg.eigvalsh(random_corr)\n",
    "        eigs = np.sort(eigs)[::-1]\n",
    "        random_eigenvalues.append(eigs)\n",
    "    random_eigenvalues = np.array(random_eigenvalues)\n",
    "    percentiles = np.percentile(random_eigenvalues, percentile, axis=0)\n",
    "    n_factors = np.sum(obs_eigenvalues > percentiles)\n",
    "    return n_factors, obs_eigenvalues, percentiles\n",
    "\n",
    "def compute_daal(loadings_df, theoretical_factors):\n",
    "    \"\"\"Compute DAAL (Dominant Average Absolute Loading)\"\"\"\n",
    "    theoretical_unique = sorted(set(theoretical_factors))\n",
    "    extracted_factors = loadings_df.columns\n",
    "    daal_matrix = []\n",
    "    for ext_factor in extracted_factors:\n",
    "        row = []\n",
    "        for theo_factor in theoretical_unique:\n",
    "            mask = [f == theo_factor for f in theoretical_factors]\n",
    "            loadings_subset = loadings_df.loc[mask, ext_factor]\n",
    "            daal_value = loadings_subset.abs().mean()\n",
    "            row.append(daal_value)\n",
    "        daal_matrix.append(row)\n",
    "    daal_df = pd.DataFrame(daal_matrix, index=extracted_factors, columns=theoretical_unique)\n",
    "    return daal_df\n",
    "\n",
    "def compute_tucker_congruence(factor_loadings, reference_loadings):\n",
    "    \"\"\"Compute Tucker congruence coefficient (phi)\"\"\"\n",
    "    numerator = np.sum(factor_loadings * reference_loadings)\n",
    "    denom = np.sqrt(np.sum(factor_loadings**2)) * np.sqrt(np.sum(reference_loadings**2))\n",
    "    return numerator / denom if denom != 0 else 0.0\n",
    "\n",
    "def create_theoretical_indicators(theoretical_factors, codes):\n",
    "    \"\"\"Create indicator matrix for theoretical factors\"\"\"\n",
    "    unique_factors = sorted(set(theoretical_factors))\n",
    "    indicators = []\n",
    "    for factor in unique_factors:\n",
    "        indicator = [1.0 if f == factor else 0.0 for f in theoretical_factors]\n",
    "        indicators.append(indicator)\n",
    "    indicators_df = pd.DataFrame(np.array(indicators).T, columns=unique_factors, index=codes)\n",
    "    return indicators_df\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe6833",
   "metadata": {},
   "source": [
    "## Load and Validate Data\n",
    "\n",
    "Load scale items from CSV and validate required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading {SCALE_CSV_PATH}...\")\n",
    "scale = pd.read_csv(SCALE_CSV_PATH)\n",
    "print(f\"Loaded {len(scale)} items\")\n",
    "\n",
    "# Validate columns\n",
    "required = ['code', 'item', 'factor']\n",
    "missing = [c for c in required if c not in scale.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "print(\"✓ Required columns present\")\n",
    "\n",
    "# Handle scoring column\n",
    "if 'scoring' in scale.columns:\n",
    "    print(\"✓ 'scoring' column found\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: 'scoring' column missing - defaulting to +1\")\n",
    "    scale['scoring'] = 1\n",
    "\n",
    "print(f\"\\nScoring: {(scale['scoring']==1).sum()} normal, {(scale['scoring']==-1).sum()} reverse\")\n",
    "print(f\"Factors: {scale['factor'].nunique()} unique\")\n",
    "print(scale['factor'].value_counts().sort_index())\n",
    "\n",
    "# Extract data\n",
    "codes = scale['code'].tolist()\n",
    "items = scale['item'].tolist()\n",
    "factors = scale['factor'].tolist()\n",
    "scoring = scale['scoring'].tolist()\n",
    "\n",
    "print(f\"\\n✓ Data validated: {len(items)} items, {len(set(factors))} factors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf88c7",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd0c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f\"✓ CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "    print(\"✓ Apple MPS\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05068282",
   "metadata": {},
   "source": [
    "## Load or Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = {}\n",
    "model_sizes = []\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    model_size = model_name.split('-')[-1]\n",
    "    model_sizes.append(model_size)\n",
    "    \n",
    "    print(f\"\\nModel: {model_name} ({model_size})\")\n",
    "    \n",
    "    # Try pregenerated\n",
    "    if USE_PREGENERATED and model_size in PREGENERATED_EMBEDDINGS:\n",
    "        npz_path = PREGENERATED_EMBEDDINGS[model_size]\n",
    "        if os.path.exists(npz_path):\n",
    "            print(f\"  Loading from {npz_path}...\")\n",
    "            data = np.load(npz_path, allow_pickle=True)\n",
    "            embeddings = data['embeddings']\n",
    "            print(f\"  ✓ Loaded: {embeddings.shape}\")\n",
    "            all_embeddings[model_size] = embeddings\n",
    "            continue\n",
    "    \n",
    "    # Generate embeddings\n",
    "    print(f\"  Generating embeddings...\")\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    embeddings = model.encode(items, show_progress_bar=True, batch_size=8, \n",
    "                              convert_to_numpy=True, normalize_embeddings=False)\n",
    "    print(f\"  ✓ Generated: {embeddings.shape}\")\n",
    "    all_embeddings[model_size] = embeddings\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs(\"embeddings\", exist_ok=True)\n",
    "    save_path = f\"embeddings/scale_items_{model_size}.npz\"\n",
    "    np.savez(save_path, embeddings=embeddings, codes=codes, items=items)\n",
    "    print(f\"  ✓ Saved to {save_path}\")\n",
    "\n",
    "print(f\"\\n✓ All embeddings ready: {list(all_embeddings.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5007e66",
   "metadata": {},
   "source": [
    "## Main PFA Pipeline Function\n",
    "\n",
    "The core function that runs all 7 steps of the Pseudo-Factor Analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1479675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pfa_for_model(model_size, embeddings, codes, items, factors, scoring,\n",
    "                       n_factors=None, rotation='promax', eigen_criteria='parallel',\n",
    "                       parallel_iter=100, random_state=42, save_dir='results'):\n",
    "    \"\"\"\n",
    "    Run complete Pseudo-Factor Analysis pipeline for one model.\n",
    "\n",
    "    Args:\n",
    "        model_size: str, e.g., \"4B\"\n",
    "        embeddings: (n_items, dim) array\n",
    "        codes: list of item codes\n",
    "        items: list of item texts\n",
    "        factors: list of theoretical factor labels\n",
    "        scoring: list of +1/-1 scoring directions\n",
    "        n_factors: int or None (None = auto via parallel analysis)\n",
    "        rotation: str, 'promax', 'oblimin', or 'varimax'\n",
    "        eigen_criteria: 'parallel' or 'eigen1'\n",
    "        parallel_iter: int, iterations for parallel analysis\n",
    "        random_state: int, for reproducibility\n",
    "        save_dir: directory to save results\n",
    "\n",
    "    Returns:\n",
    "        results: dict with all results\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"PSEUDO-FACTOR ANALYSIS: {model_size}\")\n",
    "    print('='*70)\n",
    "\n",
    "    results = {'model_size': model_size}\n",
    "\n",
    "    # Step 1: Atomic-reversed encoding\n",
    "    print(\"\\n[1/7] Applying atomic-reversed encoding...\")\n",
    "    embeddings_ar = apply_atomic_reversed(embeddings, scoring)\n",
    "    print(f\"  ✓ Shape: {embeddings_ar.shape}\")\n",
    "\n",
    "    np.save(f\"{save_dir}/embeddings_atomic_reversed_{model_size}.npy\", embeddings_ar)\n",
    "\n",
    "    # Step 2: Cosine similarity matrix\n",
    "    print(\"\\n[2/7] Computing cosine similarity matrix...\")\n",
    "    sim_matrix = cosine_similarity(embeddings_ar)\n",
    "    print(f\"  ✓ Shape: {sim_matrix.shape}\")\n",
    "\n",
    "    np.save(f\"{save_dir}/similarity_{model_size}.npy\", sim_matrix)\n",
    "    sim_df = pd.DataFrame(sim_matrix, index=codes, columns=codes)\n",
    "    sim_df.to_csv(f\"{save_dir}/similarity_{model_size}.csv\")\n",
    "\n",
    "    results['similarity_matrix'] = sim_matrix\n",
    "\n",
    "    # Step 3: Sampling adequacy tests\n",
    "    print(\"\\n[3/7] Computing KMO and Bartlett test...\")\n",
    "\n",
    "    if FACTOR_ANALYZER_AVAILABLE:\n",
    "        kmo_per_item, kmo_total = calculate_kmo(sim_matrix)\n",
    "        print(f\"  ✓ KMO overall: {kmo_total:.3f}\")\n",
    "\n",
    "        if kmo_total < 0.5:\n",
    "            print(\"    ⚠ WARNING: KMO < 0.5 (unacceptable)\")\n",
    "        elif kmo_total < 0.6:\n",
    "            print(\"    ⚠ WARNING: KMO < 0.6 (poor)\")\n",
    "        elif kmo_total < 0.7:\n",
    "            print(\"    KMO is mediocre\")\n",
    "        elif kmo_total < 0.8:\n",
    "            print(\"    KMO is middling\")\n",
    "        elif kmo_total < 0.9:\n",
    "            print(\"    KMO is meritorious\")\n",
    "        else:\n",
    "            print(\"    KMO is marvelous\")\n",
    "\n",
    "        chi_square, p_value = calculate_bartlett_sphericity(sim_matrix)\n",
    "        print(f\"  ✓ Bartlett: χ²={chi_square:.2f}, p={p_value:.4e}\")\n",
    "\n",
    "        if p_value > 0.05:\n",
    "            print(\"    ⚠ WARNING: Not significant (p > 0.05)\")\n",
    "        else:\n",
    "            print(\"    ✓ Significant (p < 0.05)\")\n",
    "\n",
    "        results['kmo_total'] = kmo_total\n",
    "        results['kmo_per_item'] = kmo_per_item\n",
    "        results['bartlett_chi2'] = chi_square\n",
    "        results['bartlett_p'] = p_value\n",
    "    else:\n",
    "        print(\"  ⚠ Skipping (factor_analyzer not available)\")\n",
    "\n",
    "    # Step 4: Parallel analysis for factor retention\n",
    "    print(\"\\n[4/7] Determining number of factors...\")\n",
    "\n",
    "    if n_factors is None:\n",
    "        if eigen_criteria == 'parallel':\n",
    "            print(f\"  Running parallel analysis ({parallel_iter} iterations)...\")\n",
    "            n_factors_auto, obs_eigs, percentile_eigs = compute_parallel_analysis(\n",
    "                sim_matrix, n_iter=parallel_iter, random_state=random_state\n",
    "            )\n",
    "            print(f\"  ✓ Suggested {n_factors_auto} factors\")\n",
    "            n_factors = max(1, n_factors_auto)\n",
    "            results['observed_eigenvalues'] = obs_eigs\n",
    "            results['percentile_eigenvalues'] = percentile_eigs\n",
    "        else:  # eigen1\n",
    "            eigs = np.linalg.eigvalsh(sim_matrix)\n",
    "            eigs = np.sort(eigs)[::-1]\n",
    "            n_factors = np.sum(eigs > 1)\n",
    "            print(f\"  ✓ Kaiser rule (eigen>1): {n_factors} factors\")\n",
    "            results['observed_eigenvalues'] = eigs\n",
    "\n",
    "    print(f\"  ✓ Extracting {n_factors} factors with {rotation} rotation\")\n",
    "    results['n_factors'] = n_factors\n",
    "\n",
    "    # Step 5: Exploratory Factor Analysis\n",
    "    print(\"\\n[5/7] Running Exploratory Factor Analysis...\")\n",
    "\n",
    "    if not FACTOR_ANALYZER_AVAILABLE:\n",
    "        print(\"  ⚠ ERROR: factor_analyzer not available!\")\n",
    "        print(\"  Install: pip install factor-analyzer\")\n",
    "        return results\n",
    "\n",
    "    fa = FactorAnalyzer(\n",
    "        n_factors=n_factors,\n",
    "        rotation=rotation,\n",
    "        method='ml',\n",
    "        rotation_kwargs={'normalize': True} if rotation in ['promax', 'oblimin'] else {}\n",
    "    )\n",
    "\n",
    "    fa.fit(sim_matrix)\n",
    "    print(\"  ✓ EFA complete\")\n",
    "\n",
    "    loadings = fa.loadings_\n",
    "    communalities = fa.get_communalities()\n",
    "    uniquenesses = fa.get_uniquenesses()\n",
    "    variance = fa.get_factor_variance()\n",
    "\n",
    "    factor_names = [f\"Factor{i+1}\" for i in range(n_factors)]\n",
    "    loadings_df = pd.DataFrame(loadings, index=codes, columns=factor_names)\n",
    "\n",
    "    print(f\"  Loadings shape: {loadings.shape}\")\n",
    "    print(f\"  Variance explained (cumulative): {variance[2][-1]:.1%}\")\n",
    "\n",
    "    loadings_df.to_csv(f\"{save_dir}/loadings_{model_size}.csv\")\n",
    "\n",
    "    variance_df = pd.DataFrame(variance, index=['SS Loadings', 'Proportion', 'Cumulative'])\n",
    "    variance_df.to_csv(f\"{save_dir}/variance_{model_size}.csv\")\n",
    "\n",
    "    communalities_df = pd.DataFrame({\n",
    "        'communality': communalities,\n",
    "        'uniqueness': uniquenesses\n",
    "    }, index=codes)\n",
    "    communalities_df.to_csv(f\"{save_dir}/communalities_{model_size}.csv\")\n",
    "\n",
    "    results['loadings'] = loadings_df\n",
    "    results['variance'] = variance\n",
    "    results['communalities'] = communalities\n",
    "    results['uniquenesses'] = uniquenesses\n",
    "\n",
    "    # Step 6: DAAL diagnostic\n",
    "    print(\"\\n[6/7] Computing DAAL...\")\n",
    "\n",
    "    daal_df = compute_daal(loadings_df, factors)\n",
    "    print(f\"  ✓ DAAL matrix: {daal_df.shape}\")\n",
    "\n",
    "    assignments = []\n",
    "    for ext_factor in daal_df.index:\n",
    "        best_theo = daal_df.loc[ext_factor].idxmax()\n",
    "        best_daal = daal_df.loc[ext_factor, best_theo]\n",
    "        assignments.append({\n",
    "            'extracted': ext_factor,\n",
    "            'assigned_to': best_theo,\n",
    "            'daal': best_daal\n",
    "        })\n",
    "\n",
    "    assignments_df = pd.DataFrame(assignments)\n",
    "    print(\"\\n  Factor assignments (DAAL):\")\n",
    "    for _, row in assignments_df.iterrows():\n",
    "        print(f\"    {row['extracted']} → {row['assigned_to']} (DAAL={row['daal']:.3f})\")\n",
    "\n",
    "    daal_df.to_csv(f\"{save_dir}/daal_{model_size}.csv\")\n",
    "\n",
    "    results['daal'] = daal_df\n",
    "    results['daal_assignments'] = assignments_df\n",
    "\n",
    "    # Step 7: Tucker congruence\n",
    "    print(\"\\n[7/7] Computing Tucker congruence...\")\n",
    "\n",
    "    theoretical_indicators = create_theoretical_indicators(factors, codes)\n",
    "\n",
    "    tucker_matrix = []\n",
    "    for ext_factor in factor_names:\n",
    "        row = []\n",
    "        for theo_factor in theoretical_indicators.columns:\n",
    "            phi = compute_tucker_congruence(\n",
    "                loadings_df[ext_factor].values,\n",
    "                theoretical_indicators[theo_factor].values\n",
    "            )\n",
    "            row.append(phi)\n",
    "        tucker_matrix.append(row)\n",
    "\n",
    "    tucker_df = pd.DataFrame(\n",
    "        tucker_matrix,\n",
    "        index=factor_names,\n",
    "        columns=theoretical_indicators.columns\n",
    "    )\n",
    "\n",
    "    print(f\"  ✓ Tucker matrix: {tucker_df.shape}\")\n",
    "    print(\"\\n  Interpretation guide:\")\n",
    "    print(\"    φ ≥ .95: Excellent agreement\")\n",
    "    print(\"    φ ≥ .85: Fair agreement\")\n",
    "    print(\"    φ < .85: Poor agreement\")\n",
    "\n",
    "    tucker_best = []\n",
    "    for ext_factor in tucker_df.index:\n",
    "        best_theo = tucker_df.loc[ext_factor].idxmax()\n",
    "        best_phi = tucker_df.loc[ext_factor, best_theo]\n",
    "        tucker_best.append({\n",
    "            'extracted': ext_factor,\n",
    "            'best_match': best_theo,\n",
    "            'tucker_phi': best_phi\n",
    "        })\n",
    "\n",
    "    tucker_best_df = pd.DataFrame(tucker_best)\n",
    "    print(\"\\n  Best matches (Tucker φ):\")\n",
    "    for _, row in tucker_best_df.iterrows():\n",
    "        print(f\"    {row['extracted']} ↔ {row['best_match']} (φ={row['tucker_phi']:.3f})\")\n",
    "\n",
    "    tucker_df.to_csv(f\"{save_dir}/tucker_{model_size}.csv\")\n",
    "\n",
    "    results['tucker'] = tucker_df\n",
    "    results['tucker_best'] = tucker_best_df\n",
    "\n",
    "    # Combined diagnostics\n",
    "    diagnostics = {\n",
    "        'model': model_size,\n",
    "        'n_items': len(codes),\n",
    "        'n_factors_extracted': n_factors,\n",
    "        'rotation': rotation,\n",
    "    }\n",
    "\n",
    "    if FACTOR_ANALYZER_AVAILABLE:\n",
    "        diagnostics['kmo'] = kmo_total\n",
    "        diagnostics['bartlett_p'] = p_value\n",
    "\n",
    "    diagnostics['variance_explained'] = variance[2][-1]\n",
    "\n",
    "    diagnostics_df = pd.DataFrame([diagnostics])\n",
    "    diagnostics_df.to_csv(f\"{save_dir}/diagnostics_{model_size}.csv\", index=False)\n",
    "\n",
    "    results['diagnostics'] = diagnostics_df\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"✓ PFA COMPLETE FOR {model_size}\")\n",
    "    print('='*70)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f07f4e",
   "metadata": {},
   "source": [
    "## Visualization Function\n",
    "\n",
    "Create comprehensive visualizations of PFA results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(results, factors, codes, model_size, save_dir='results'):\n",
    "    \"\"\"Create all visualizations for PFA results\"\"\"\n",
    "\n",
    "    print(f\"\\nCreating visualizations for {model_size}...\")\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "    # 1. Scree plot\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    if 'observed_eigenvalues' in results:\n",
    "        obs_eigs = results['observed_eigenvalues']\n",
    "        n_show = min(20, len(obs_eigs))\n",
    "        ax1.plot(range(1, n_show + 1), obs_eigs[:n_show], 'o-', label='Observed', linewidth=2)\n",
    "\n",
    "        if 'percentile_eigenvalues' in results:\n",
    "            perc_eigs = results['percentile_eigenvalues']\n",
    "            ax1.plot(range(1, n_show + 1), perc_eigs[:n_show], 's--',\n",
    "                    label='95th percentile (random)', linewidth=2)\n",
    "\n",
    "        ax1.axhline(1, color='red', linestyle='--', alpha=0.5, label='Eigen = 1')\n",
    "        ax1.set_xlabel('Factor Number')\n",
    "        ax1.set_ylabel('Eigenvalue')\n",
    "        ax1.set_title(f'Scree Plot - {model_size}')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Similarity matrix heatmap\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    if 'similarity_matrix' in results:\n",
    "        sim = results['similarity_matrix']\n",
    "        factor_order = sorted(range(len(factors)), key=lambda i: (factors[i], i))\n",
    "        sim_ordered = sim[factor_order][:, factor_order]\n",
    "\n",
    "        sns.heatmap(sim_ordered, cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n",
    "                   square=True, ax=ax2, cbar_kws={'label': 'Cosine Similarity'})\n",
    "        ax2.set_title(f'Similarity Matrix - {model_size}')\n",
    "        ax2.set_xlabel('Items')\n",
    "        ax2.set_ylabel('Items')\n",
    "\n",
    "    # 3. Loadings heatmap\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    if 'loadings' in results:\n",
    "        loadings_df = results['loadings']\n",
    "        factor_order = sorted(range(len(factors)), key=lambda i: (factors[i], i))\n",
    "        ordered_loadings = loadings_df.loc[[codes[i] for i in factor_order]]\n",
    "\n",
    "        sns.heatmap(ordered_loadings.values, cmap='RdBu_r', center=0,\n",
    "                   vmin=-1, vmax=1, ax=ax3, cbar_kws={'label': 'Loading'})\n",
    "        ax3.set_title(f'Factor Loadings - {model_size}')\n",
    "        ax3.set_xlabel('Extracted Factors')\n",
    "        ax3.set_ylabel('Items')\n",
    "        ax3.set_yticks([])\n",
    "\n",
    "    # 4. DAAL heatmap\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    if 'daal' in results:\n",
    "        daal = results['daal']\n",
    "        sns.heatmap(daal.values, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "                   xticklabels=daal.columns, yticklabels=daal.index,\n",
    "                   ax=ax4, cbar_kws={'label': 'DAAL'})\n",
    "        ax4.set_title(f'DAAL Matrix - {model_size}')\n",
    "        ax4.set_xlabel('Theoretical Factors')\n",
    "        ax4.set_ylabel('Extracted Factors')\n",
    "\n",
    "    # 5. Tucker congruence heatmap\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    if 'tucker' in results:\n",
    "        tucker = results['tucker']\n",
    "        sns.heatmap(tucker.values, annot=True, fmt='.3f', cmap='YlGnBu',\n",
    "                   xticklabels=tucker.columns, yticklabels=tucker.index,\n",
    "                   ax=ax5, vmin=0, vmax=1, cbar_kws={'label': 'Tucker φ'})\n",
    "        ax5.set_title(f'Tucker Congruence - {model_size}')\n",
    "        ax5.set_xlabel('Theoretical Factors')\n",
    "        ax5.set_ylabel('Extracted Factors')\n",
    "\n",
    "    # 6. Tucker best matches bar plot\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    if 'tucker_best' in results:\n",
    "        tucker_best = results['tucker_best']\n",
    "        colors = ['green' if x >= 0.95 else 'orange' if x >= 0.85 else 'red'\n",
    "                 for x in tucker_best['tucker_phi']]\n",
    "        ax6.barh(tucker_best['extracted'], tucker_best['tucker_phi'], color=colors)\n",
    "        ax6.axvline(0.95, color='green', linestyle='--', alpha=0.5, label='Excellent (≥.95)')\n",
    "        ax6.axvline(0.85, color='orange', linestyle='--', alpha=0.5, label='Fair (≥.85)')\n",
    "        ax6.set_xlabel('Tucker φ')\n",
    "        ax6.set_ylabel('Extracted Factor')\n",
    "        ax6.set_title(f'Best Tucker Congruence - {model_size}')\n",
    "        ax6.legend()\n",
    "        ax6.set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/visualizations_{model_size}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"  ✓ Saved: {save_dir}/visualizations_{model_size}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be916eab",
   "metadata": {},
   "source": [
    "## Run PFA for All Models\n",
    "\n",
    "Execute the complete pipeline for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    embeddings = all_embeddings[model_size]\n",
    "    \n",
    "    results = run_pfa_for_model(\n",
    "        model_size=model_size,\n",
    "        embeddings=embeddings,\n",
    "        codes=codes,\n",
    "        items=items,\n",
    "        factors=factors,\n",
    "        scoring=scoring,\n",
    "        n_factors=N_FACTORS,\n",
    "        rotation=ROTATION_METHOD,\n",
    "        eigen_criteria=EIGEN_CRITERIA,\n",
    "        parallel_iter=PARALLEL_ITER,\n",
    "        random_state=RANDOM_STATE,\n",
    "        save_dir=SAVE_DIR\n",
    "    )\n",
    "    \n",
    "    all_results[model_size] = results\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_visualizations(results, factors, codes, model_size, save_dir=SAVE_DIR)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ PFA COMPLETE FOR ALL MODELS\")\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zqk8j9twir8",
   "metadata": {},
   "source": [
    "## Analyze Nearest Neighbors - All Models\n",
    "\n",
    "Examine nearest neighbors in the original high-dimensional embedding space to validate semantic clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmx9ga481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample item to analyze\n",
    "sample_idx = 0  # First item\n",
    "\n",
    "print(\"Finding nearest neighbors in original embedding space...\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nSample item #{sample_idx}:\")\n",
    "print(f\"  Code: {codes[sample_idx]}\")\n",
    "print(f\"  Factor: {factors[sample_idx]}\")\n",
    "print(f\"  Text: {items[sample_idx]}\")\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    embeddings = all_embeddings[model_size]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_size} Model - Original {embeddings.shape[1]}D Space\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Compute cosine similarity between sample and all items\n",
    "    # Note: embeddings are already processed through atomic-reversed encoding\n",
    "    # For pure nearest neighbors, we could use original embeddings, but using\n",
    "    # the processed ones ensures consistency with the PFA analysis\n",
    "    similarities = cosine_similarity([embeddings[sample_idx]], embeddings)[0]\n",
    "    \n",
    "    # Find 5 most similar items (excluding itself)\n",
    "    most_similar_indices = np.argsort(similarities)[::-1][1:6]\n",
    "    \n",
    "    print(f\"5 Most similar items (by cosine similarity):\")\n",
    "    for rank, idx in enumerate(most_similar_indices, 1):\n",
    "        print(f\"  {rank}. [{factors[idx]}] {items[idx][:80]}...\")\n",
    "        print(f\"      Similarity: {similarities[idx]:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ Nearest neighbors analysis complete\")\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fonl4szhx2i",
   "metadata": {},
   "source": [
    "## Within- vs Between-Construct Similarity Analysis (Milano et al. 2025)\n",
    "\n",
    "Test whether items from the same theoretical factor are more similar than items from different factors.\n",
    "\n",
    "**Method:**\n",
    "- **Within-construct similarities**: Cosine similarities between items sharing the same factor\n",
    "- **Between-construct similarities**: Cosine similarities between items from different factors\n",
    "- **Statistical test**: Welch's t-test (unequal variances)\n",
    "- **Effect size**: Cohen's d\n",
    "\n",
    "This analysis provides empirical evidence for **construct validity**: if embeddings capture the theoretical factor structure, within-construct similarities should be significantly higher than between-construct similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mqkx9ecejim",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MILANO ET AL. (2025) WITHIN- vs BETWEEN-CONSTRUCT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    print(f\"\\n{model_size} Model:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Get similarity matrix from results\n",
    "    sim_matrix = all_results[model_size]['similarity_matrix']\n",
    "    n_items = len(factors)\n",
    "    \n",
    "    # Collect similarities (upper triangle only, i < j)\n",
    "    within_sims = []\n",
    "    between_sims = []\n",
    "    \n",
    "    for i in range(n_items):\n",
    "        for j in range(i + 1, n_items):  # Upper triangle only\n",
    "            sim = sim_matrix[i, j]\n",
    "            \n",
    "            if factors[i] == factors[j]:\n",
    "                within_sims.append(sim)\n",
    "            else:\n",
    "                between_sims.append(sim)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    within_sims = np.array(within_sims)\n",
    "    between_sims = np.array(between_sims)\n",
    "    \n",
    "    # Compute statistics\n",
    "    mean_within = np.mean(within_sims)\n",
    "    sd_within = np.std(within_sims, ddof=1)\n",
    "    mean_between = np.mean(between_sims)\n",
    "    sd_between = np.std(between_sims, ddof=1)\n",
    "    mean_diff = mean_within - mean_between\n",
    "    \n",
    "    # Cohen's d (pooled standard deviation)\n",
    "    pooled_sd = np.sqrt((sd_within**2 + sd_between**2) / 2)\n",
    "    cohens_d = mean_diff / pooled_sd if pooled_sd > 0 else 0.0\n",
    "    \n",
    "    # Welch's t-test (unequal variances)\n",
    "    t_stat, p_value = ttest_ind(within_sims, between_sims, equal_var=False)\n",
    "    \n",
    "    # Degrees of freedom (Welch-Satterthwaite)\n",
    "    n1, n2 = len(within_sims), len(between_sims)\n",
    "    s1_sq, s2_sq = sd_within**2, sd_between**2\n",
    "    df = (s1_sq/n1 + s2_sq/n2)**2 / ((s1_sq/n1)**2/(n1-1) + (s2_sq/n2)**2/(n2-1))\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"  Within-construct:  M = {mean_within:.3f}, SD = {sd_within:.3f}, n = {len(within_sims)}\")\n",
    "    print(f\"  Between-construct: M = {mean_between:.3f}, SD = {sd_between:.3f}, n = {len(between_sims)}\")\n",
    "    print(f\"  Mean difference: {mean_diff:.3f}\")\n",
    "    print(f\"  Welch's t({df:.1f}) = {t_stat:.2f}, p = {p_value:.4e}\")\n",
    "    print(f\"  Cohen's d = {cohens_d:.3f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if p_value < 0.001:\n",
    "        sig_text = \"highly significant (p < .001)\"\n",
    "    elif p_value < 0.01:\n",
    "        sig_text = \"very significant (p < .01)\"\n",
    "    elif p_value < 0.05:\n",
    "        sig_text = \"significant (p < .05)\"\n",
    "    else:\n",
    "        sig_text = \"not significant (p ≥ .05)\"\n",
    "    \n",
    "    if abs(cohens_d) >= 0.8:\n",
    "        effect_text = \"large effect\"\n",
    "    elif abs(cohens_d) >= 0.5:\n",
    "        effect_text = \"medium effect\"\n",
    "    elif abs(cohens_d) >= 0.2:\n",
    "        effect_text = \"small effect\"\n",
    "    else:\n",
    "        effect_text = \"negligible effect\"\n",
    "    \n",
    "    print(f\"\\n  Interpretation: {sig_text}, {effect_text}\")\n",
    "    \n",
    "    if mean_within > mean_between and p_value < 0.05:\n",
    "        print(f\"  ✓ Items from the same factor are significantly more similar.\")\n",
    "    elif mean_within < mean_between and p_value < 0.05:\n",
    "        print(f\"  ⚠ Items from different factors are MORE similar (unexpected!).\")\n",
    "    else:\n",
    "        print(f\"  ⚠ No significant difference in within- vs between-construct similarity.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ MILANO ET AL. ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33n4e9n0snf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize within vs between similarities\n",
    "print(\"\\nCreating Milano et al. visualization...\")\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    sim_matrix = all_results[model_size]['similarity_matrix']\n",
    "    n_items = len(factors)\n",
    "    \n",
    "    # Collect similarities\n",
    "    within_sims = []\n",
    "    between_sims = []\n",
    "    \n",
    "    for i in range(n_items):\n",
    "        for j in range(i + 1, n_items):\n",
    "            sim = sim_matrix[i, j]\n",
    "            if factors[i] == factors[j]:\n",
    "                within_sims.append(sim)\n",
    "            else:\n",
    "                between_sims.append(sim)\n",
    "    \n",
    "    # Create violin plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    data = [within_sims, between_sims]\n",
    "    positions = [1, 2]\n",
    "    \n",
    "    parts = ax.violinplot(data, positions=positions, showmeans=True, showmedians=True)\n",
    "    \n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(['Within-Construct', 'Between-Construct'])\n",
    "    ax.set_ylabel('Cosine Similarity')\n",
    "    ax.set_title(f'Milano et al. (2025) Analysis - {model_size}\\nWithin- vs Between-Construct Similarities')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add mean values as text\n",
    "    mean_within = np.mean(within_sims)\n",
    "    mean_between = np.mean(between_sims)\n",
    "    \n",
    "    ax.text(1, mean_within, f'M={mean_within:.3f}', \n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.text(2, mean_between, f'M={mean_between:.3f}', \n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add sample sizes\n",
    "    ax.text(1, ax.get_ylim()[0], f'n={len(within_sims)}', \n",
    "            ha='center', va='top', fontsize=9, style='italic')\n",
    "    ax.text(2, ax.get_ylim()[0], f'n={len(between_sims)}', \n",
    "            ha='center', va='top', fontsize=9, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{SAVE_DIR}/milano_analysis_{model_size}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"  ✓ Saved: {SAVE_DIR}/milano_analysis_{model_size}.png\")\n",
    "\n",
    "print(\"\\n✓ Milano et al. visualizations complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf2406",
   "metadata": {},
   "source": [
    "## Summary Report\n",
    "\n",
    "Display key diagnostics and results for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    results = all_results[model_size]\n",
    "    print(f\"\\n{model_size}:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if 'diagnostics' in results:\n",
    "        diag = results['diagnostics'].iloc[0]\n",
    "        print(f\"  Items: {diag['n_items']}\")\n",
    "        print(f\"  Factors: {diag['n_factors_extracted']}\")\n",
    "        print(f\"  Rotation: {diag['rotation']}\")\n",
    "        if 'kmo' in diag:\n",
    "            print(f\"  KMO: {diag['kmo']:.3f}\")\n",
    "        if 'bartlett_p' in diag:\n",
    "            print(f\"  Bartlett p: {diag['bartlett_p']:.4e}\")\n",
    "        print(f\"  Variance: {diag['variance_explained']:.1%}\")\n",
    "    \n",
    "    if 'daal_assignments' in results:\n",
    "        print(\"\\n  DAAL assignments:\")\n",
    "        for _, row in results['daal_assignments'].iterrows():\n",
    "            print(f\"    {row['extracted']} → {row['assigned_to']} (DAAL={row['daal']:.3f})\")\n",
    "    \n",
    "    if 'tucker_best' in results:\n",
    "        print(\"\\n  Tucker congruence:\")\n",
    "        for _, row in results['tucker_best'].iterrows():\n",
    "            print(f\"    {row['extracted']} ↔ {row['best_match']} (φ={row['tucker_phi']:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nResults saved to: {SAVE_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f7fb4",
   "metadata": {},
   "source": [
    "## Automatic Factor Naming with LLM\n",
    "\n",
    "Generate semantic names for EFA-extracted factors using Qwen2.5-1.5B-Instruct.\n",
    "\n",
    "**Approach:**\n",
    "1. For each extracted factor, identify the top 10 items with highest absolute loadings\n",
    "2. Extract the text of these high-loading items\n",
    "3. Feed the item text to Qwen2.5-1.5B-Instruct LLM with a prompt\n",
    "4. LLM generates a concise semantic label (single word or short phrase) describing what the items measure\n",
    "5. Store factor name mappings in `factor_name_mappings` dictionary\n",
    "\n",
    "**Prompt Format:**\n",
    "```\n",
    "\"These are items from a psychological scale that all load strongly on the same latent factor: [item1 | item2 | ...]. \n",
    "Provide a single word or very short phrase that best describes the psychological construct these items are measuring.\"\n",
    "```\n",
    "\n",
    "**Advantages over vocabulary-based naming:**\n",
    "- Uses actual scale items that define each factor (not external vocabulary)\n",
    "- More psychologically valid (factors are defined by their indicators)\n",
    "- No need to load separate word embeddings\n",
    "- Direct relationship between loadings and names\n",
    "\n",
    "**Note:** Generated names are stored in the `factor_name_mappings` dictionary. Original results in `all_results` remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "\n",
    "print(\"Loading Qwen/Qwen2.5-1.5B-Instruct...\")\n",
    "llm_model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "try:\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "    \n",
    "    # Load model and move to appropriate device\n",
    "    llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "        llm_model_name,\n",
    "        dtype=torch.float32,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    llm_model = llm_model.to(device)\n",
    "    llm_model.eval()\n",
    "    \n",
    "    print(f\"✓ Qwen/Qwen2.5-1.5B-Instruct loaded successfully!\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Error loading {llm_model_name}:\")\n",
    "    print(f\"  {type(e).__name__}: {str(e)}\")\n",
    "    print(f\"\\nSkipping automatic factor naming...\")\n",
    "    llm_model = None\n",
    "\n",
    "# Proceed with factor naming if model loaded successfully\n",
    "if llm_model is not None:\n",
    "    print(f\"\\nGenerating semantic names for extracted factors...\\n\")\n",
    "    \n",
    "    # Define system prompt\n",
    "    system_prompt = \"You are a helpful assistant that provides concise, one or two-word summaries.\"\n",
    "    print(f\"System prompt: {system_prompt}\\n\")\n",
    "    \n",
    "    # Store factor name mappings\n",
    "    factor_name_mappings = {}\n",
    "    \n",
    "    # Process each model\n",
    "    for model_size in model_sizes:\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"{model_size} Model - Automatic Factor Naming\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Get loadings for this model\n",
    "        loadings_df = all_results[model_size]['loadings']\n",
    "        n_factors = loadings_df.shape[1]\n",
    "        \n",
    "        factor_name_mappings[model_size] = {}\n",
    "        \n",
    "        # Process each factor\n",
    "        for factor_name in loadings_df.columns:\n",
    "            print(f\"\\n{factor_name}:\")\n",
    "            print(\"-\"*70)\n",
    "            \n",
    "            # Get absolute loadings for this factor (to find strongest indicators)\n",
    "            factor_loadings = loadings_df[factor_name].abs()\n",
    "            \n",
    "            # Find top 10 items with highest absolute loadings\n",
    "            top_indices = factor_loadings.nlargest(10).index\n",
    "            \n",
    "            # Get the actual item text for these top-loading items\n",
    "            top_items_text = []\n",
    "            print(f\"Top loading items:\")\n",
    "            for i, code in enumerate(top_indices, 1):\n",
    "                item_idx = codes.index(code)\n",
    "                item_text = items[item_idx]\n",
    "                loading_val = loadings_df.loc[code, factor_name]\n",
    "                top_items_text.append(item_text)\n",
    "                print(f\"  {i}. [{code}] (λ={loading_val:.3f}): {item_text[:70]}...\")\n",
    "            \n",
    "            # Create prompt from top 5 items (truncate for context length)\n",
    "            items_for_prompt = \" | \".join([item[:120] for item in top_items_text[:5]])\n",
    "            \n",
    "            user_prompt = f\"\"\"These are items from a psychological scale that all load strongly on the same latent factor:\n",
    "\n",
    "{items_for_prompt}\n",
    "\n",
    "Provide a single word or very short phrase (maximum 3 words) that best describes the psychological construct these items are measuring. Provide ONLY the label, nothing else.\"\"\"\n",
    "            \n",
    "            # Create messages for chat template\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            \n",
    "            # Apply chat template\n",
    "            text = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            \n",
    "            # Tokenize\n",
    "            inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Generate with greedy decoding\n",
    "            with torch.no_grad():\n",
    "                outputs = llm_model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=10,\n",
    "                    do_sample=False,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            # Decode only the new tokens\n",
    "            generated_text = tokenizer.decode(\n",
    "                outputs[0][inputs['input_ids'].shape[1]:], \n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            \n",
    "            # Extract and clean the generated name\n",
    "            generated_name = generated_text.strip()\n",
    "            generated_name = re.sub(r'^[\"\\'\\s]+|[\"\\'\\s]+$', '', generated_name)\n",
    "            generated_name = re.sub(r'[.,;:!?]+$', '', generated_name)\n",
    "            generated_name = generated_name.split('\\n')[0].strip()\n",
    "            \n",
    "            if len(generated_name) > 50:\n",
    "                generated_name = generated_name[:50].strip()\n",
    "            \n",
    "            # If generation failed or is empty, keep original name\n",
    "            if not generated_name or len(generated_name) < 2:\n",
    "                generated_name = factor_name\n",
    "            \n",
    "            print(f\"\\nGenerated name: '{generated_name}'\")\n",
    "            \n",
    "            # Store the mapping\n",
    "            factor_name_mappings[model_size][factor_name] = generated_name\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✓ Automatic factor naming complete!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Display summary of all mappings\n",
    "    print(\"\\nFactor Name Mappings Summary:\")\n",
    "    print(\"=\"*70)\n",
    "    for model_size in model_sizes:\n",
    "        print(f\"\\n{model_size}:\")\n",
    "        for old_name, new_name in factor_name_mappings[model_size].items():\n",
    "            print(f\"  {old_name} → '{new_name}'\")\n",
    "    \n",
    "    # Optionally update the results with new names\n",
    "    print(\"\\nNote: Factor names are stored in 'factor_name_mappings' dictionary.\")\n",
    "    print(\"Original results in 'all_results' remain unchanged.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n⚠ Skipping automatic factor naming due to model loading failure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1703795",
   "metadata": {},
   "source": [
    "## T-SNE Visualizations: Original Factors vs EFA-Extracted Factors\n",
    "\n",
    "Create T-SNE visualizations comparing original theoretical factor assignments with EFA-extracted factor assignments.\n",
    "\n",
    "**Two-plot comparison:**\n",
    "- **Plot 1 (Top)**: Items colored by original theoretical factors (from CSV 'factor' column)\n",
    "- **Plot 2 (Bottom)**: Items colored by extracted EFA factors (assigned by highest loading)\n",
    "  - Uses LLM-generated factor names if available\n",
    "  - Falls back to \"Factor1\", \"Factor2\", etc. if LLM naming hasn't run\n",
    "\n",
    "**Visualization details:**\n",
    "- 2D visualization via t-SNE dimensionality reduction\n",
    "- Color-coded by factor with item codes labeled\n",
    "- Separate files saved for each visualization type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5v773a5wd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create factor assignments based on highest loadings\n",
    "print(\"Creating factor assignments from EFA loadings...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "factor_assignments = {}\n",
    "\n",
    "for model_size in model_sizes:\n",
    "    loadings_df = all_results[model_size]['loadings']\n",
    "    \n",
    "    # For each item, find the factor with highest absolute loading\n",
    "    item_to_factor = {}\n",
    "    \n",
    "    for item_code in loadings_df.index:\n",
    "        # Get absolute loadings for this item across all factors\n",
    "        abs_loadings = loadings_df.loc[item_code].abs()\n",
    "        # Find factor with highest loading\n",
    "        assigned_factor = abs_loadings.idxmax()\n",
    "        item_to_factor[item_code] = assigned_factor\n",
    "    \n",
    "    # Group items by their assigned factors\n",
    "    factor_items = {}\n",
    "    for factor_name in loadings_df.columns:\n",
    "        # Find all items assigned to this factor\n",
    "        assigned_items = [\n",
    "            {'index': codes.index(code), 'code': code}\n",
    "            for code, assigned_f in item_to_factor.items()\n",
    "            if assigned_f == factor_name\n",
    "        ]\n",
    "        factor_items[factor_name] = assigned_items\n",
    "    \n",
    "    factor_assignments[model_size] = factor_items\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\n{model_size}:\")\n",
    "    for factor_name, items_list in factor_items.items():\n",
    "        # Get display name (LLM-generated or default)\n",
    "        if 'factor_name_mappings' in dir() and model_size in factor_name_mappings:\n",
    "            display_name = factor_name_mappings[model_size].get(factor_name, factor_name)\n",
    "        else:\n",
    "            display_name = factor_name\n",
    "        \n",
    "        print(f\"  {factor_name} ('{display_name}'): {len(items_list)} items\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Factor assignments created!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Prepare data for T-SNE (same across all models)\n",
    "print(\"Preparing data for T-SNE...\")\n",
    "print(f\"Number of items: {len(factors)}\")\n",
    "\n",
    "# Get unique factors for legend\n",
    "print(f\"Factors: {unique_factors}\")\n",
    "\n",
    "# Create a color map for the personality factors\n",
    "import matplotlib.cm as cm\n",
    "colors_map = cm.get_cmap('tab10', len(unique_factors))\n",
    "factor_to_color = {factor: colors_map(i) for i, factor in enumerate(unique_factors)}\n",
    "\n",
    "# Run T-SNE and create visualizations for all models\n",
    "print(\"Running T-SNE for all models...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_tsne_embeddings = {}\n",
    "\n",
    "for model_size, embeddings in all_embeddings.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Running T-SNE for {model_size} model...\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Input shape: {embeddings.shape}\")\n",
    "    \n",
    "    # Run T-SNE dimensionality reduction\n",
    "    tsne = TSNE(\n",
    "        n_components=2,      # Reduce to 2D\n",
    "        perplexity=25,       # Balance local vs global structure\n",
    "        max_iter=1000,       # Number of iterations\n",
    "        random_state=42,     # For reproducibility\n",
    "        verbose=1            # Show progress\n",
    "    )\n",
    "    \n",
    "    # Transform high-D embeddings to 2D\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "    all_tsne_embeddings[model_size] = embeddings_2d\n",
    "    \n",
    "    print(f\"✓ T-SNE complete! 2D embeddings shape: {embeddings_2d.shape}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✓ T-SNE complete for all {len(all_tsne_embeddings)} models!\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create T-SNE scatter plots for all models\n",
    "print(\"Creating T-SNE visualizations...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "print(f\"Plots will be saved to: {plots_dir}/\")\n",
    "\n",
    "# Generate timestamp for filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Determine number of models\n",
    "num_models = len(all_tsne_embeddings)\n",
    "print(f\"Creating plots for {num_models} model(s)...\")\n",
    "\n",
    "# Check if we have any models to plot\n",
    "if num_models == 0:\n",
    "    print(\"\\n⚠ WARNING: No T-SNE embeddings available to plot!\")\n",
    "    print(\"  Please run the T-SNE computation cells first.\")\n",
    "    print(\"\\nSkipping visualization...\")\n",
    "else:\n",
    "    # Check if EFA factor assignments are available\n",
    "    factor_assignments_available = 'factor_assignments' in dir() and len(factor_assignments) > 0\n",
    "    \n",
    "    if not factor_assignments_available:\n",
    "        print(\"\\n⚠ WARNING: EFA factor assignments not available!\")\n",
    "        print(\"  Please run the PCA analysis cell first.\")\n",
    "        print(\"  Will show original factor coloring only.\\n\")\n",
    "    \n",
    "    # Create main combined plot with 2 rows (if PCA assignments available)\n",
    "    if factor_assignments_available:\n",
    "        # 2 rows: top = original factors, bottom = EFA factors\n",
    "        fig_width = min(24, 8 * num_models)\n",
    "        fig, axes = plt.subplots(2, min(3, num_models), figsize=(fig_width, 16))\n",
    "        \n",
    "        # Handle case of single model\n",
    "        if min(3, num_models) == 1:\n",
    "            axes = axes.reshape(2, 1)\n",
    "    else:\n",
    "        # Single row: original factors only\n",
    "        fig_width = min(24, 8 * num_models)\n",
    "        fig, axes = plt.subplots(1, min(3, num_models), figsize=(fig_width, 8))\n",
    "        \n",
    "        if min(3, num_models) == 1:\n",
    "            axes = [axes]\n",
    "    \n",
    "    # Plot each model\n",
    "    for idx, (model_size, embeddings_2d) in enumerate(sorted(all_tsne_embeddings.items())):\n",
    "        if idx >= 3:  # Only plot first 3 models\n",
    "            break\n",
    "        \n",
    "        # Get embedding dimension for titles\n",
    "        embedding_dim = all_embeddings[model_size].shape[1]\n",
    "        \n",
    "        # ===== ROW 1: Original Factors =====\n",
    "        if factor_assignments_available:\n",
    "            ax = axes[0, idx]\n",
    "        else:\n",
    "            ax = axes[idx] if isinstance(axes, list) else axes\n",
    "        \n",
    "        # Plot each original factor with a different color\n",
    "        for factor in unique_factors:\n",
    "            indices = [i for i, f in enumerate(factors) if f == factor]\n",
    "            ax.scatter(\n",
    "                embeddings_2d[indices, 0],\n",
    "                embeddings_2d[indices, 1],\n",
    "                c=[factor_to_color[factor]],\n",
    "                label=factor,\n",
    "                alpha=0.6,\n",
    "                s=80,\n",
    "                edgecolors='white',\n",
    "                linewidth=0.5\n",
    "            )\n",
    "        \n",
    "        # Add labels\n",
    "        for i in range(len(embeddings_2d)):\n",
    "            ax.annotate(\n",
    "                codes[i],\n",
    "                (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                fontsize=7,\n",
    "                alpha=0.7,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                xytext=(0, 3),\n",
    "                textcoords='offset points'\n",
    "            )\n",
    "        \n",
    "        ax.set_xlabel('T-SNE Component 1', fontsize=11)\n",
    "        ax.set_ylabel('T-SNE Component 2', fontsize=11)\n",
    "        ax.set_title(\n",
    "            f'{model_size} Model - Original Factors\\n({embedding_dim}D → 2D)',\n",
    "            fontsize=13,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Add legend to rightmost plot\n",
    "        if idx == min(2, num_models - 1):\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "        \n",
    "        # ===== ROW 2: EFA Factors =====\n",
    "        if factor_assignments_available:\n",
    "            ax = axes[1, idx]\n",
    "            \n",
    "            # Get component assignments for this model\n",
    "            factor_items = factor_assignments[model_size]\n",
    "            n_factors = len(factor_items)\n",
    "            \n",
    "            # Create color map for components\n",
    "            factor_colors_map = plt.cm.get_cmap('tab10', n_factors)\n",
    "            factor_names = sorted(factor_items.keys())\n",
    "            factor_to_color = {comp: factor_colors_map(i) for i, comp in enumerate(factor_names)}\n",
    "            \n",
    "            # Plot each component with a different color\n",
    "            for factor_name in factor_names:\n",
    "                # Get display name (LLM-generated or default)\n",
    "                if 'factor_name_mappings' in dir() and model_size in factor_name_mappings:\n",
    "                    display_name = factor_name_mappings[model_size].get(factor_name, factor_name)\n",
    "                else:\n",
    "                    display_name = factor_name\n",
    "\n",
    "                indices = [item['index'] for item in factor_items[factor_name]]\n",
    "                if len(indices) > 0:\n",
    "                    ax.scatter(\n",
    "                        embeddings_2d[indices, 0],\n",
    "                        embeddings_2d[indices, 1],\n",
    "                        c=[factor_to_color[factor_name]],\n",
    "                        label=display_name,\n",
    "                        alpha=0.6,\n",
    "                        s=80,\n",
    "                        edgecolors='white',\n",
    "                        linewidth=0.5\n",
    "                    )\n",
    "            \n",
    "            # Add labels\n",
    "            for i in range(len(embeddings_2d)):\n",
    "                ax.annotate(\n",
    "                    codes[i],\n",
    "                    (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                    fontsize=7,\n",
    "                    alpha=0.7,\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords='offset points'\n",
    "                )\n",
    "            \n",
    "            ax.set_xlabel('T-SNE Component 1', fontsize=11)\n",
    "            ax.set_ylabel('T-SNE Component 2', fontsize=11)\n",
    "            ax.set_title(\n",
    "                f'{model_size} Model - EFA Factors\\n({embedding_dim}D → 2D)',\n",
    "                fontsize=13,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            \n",
    "            # Add legend to rightmost plot\n",
    "            if idx == min(2, num_models - 1):\n",
    "                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    \n",
    "    # Overall title\n",
    "    if factor_assignments_available:\n",
    "        fig.suptitle(\n",
    "            'T-SNE Visualization of Scale Item Embeddings',\n",
    "            fontsize=16,\n",
    "            fontweight='bold',\n",
    "            y=0.995\n",
    "        )\n",
    "    else:\n",
    "        fig.suptitle(\n",
    "            'T-SNE Visualization of Scale Item Embeddings - Original Factors',\n",
    "            fontsize=16,\n",
    "            fontweight='bold',\n",
    "            y=1.00\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the combined figure\n",
    "    model_names_str = \"_\".join(sorted(list(all_tsne_embeddings.keys())[:3]))\n",
    "    if factor_assignments_available:\n",
    "        filename = f\"qwen3_tsne_combined_{model_names_str}_{timestamp}.png\"\n",
    "    else:\n",
    "        filename = f\"qwen3_tsne_original_{model_names_str}_{timestamp}.png\"\n",
    "    filepath = os.path.join(plots_dir, filename)\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Combined plot saved to: {filepath}\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # ===== Save Individual Plots =====\n",
    "    if factor_assignments_available:\n",
    "        print(f\"\\nCreating individual plots...\")\n",
    "        \n",
    "        for model_size, embeddings_2d in sorted(all_tsne_embeddings.items()):\n",
    "            embedding_dim = all_embeddings[model_size].shape[1]\n",
    "            \n",
    "            # Individual plot 1: Original Factors\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "            \n",
    "            for factor in unique_factors:\n",
    "                indices = [i for i, f in enumerate(factors) if f == factor]\n",
    "                ax.scatter(\n",
    "                    embeddings_2d[indices, 0],\n",
    "                    embeddings_2d[indices, 1],\n",
    "                    c=[factor_to_color[factor]],\n",
    "                    label=factor,\n",
    "                    alpha=0.6,\n",
    "                    s=80,\n",
    "                    edgecolors='white',\n",
    "                    linewidth=0.5\n",
    "                )\n",
    "            \n",
    "            for i in range(len(embeddings_2d)):\n",
    "                ax.annotate(\n",
    "                    codes[i],\n",
    "                    (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                    fontsize=7,\n",
    "                    alpha=0.7,\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords='offset points'\n",
    "                )\n",
    "            \n",
    "            ax.set_xlabel('T-SNE Component 1', fontsize=11)\n",
    "            ax.set_ylabel('T-SNE Component 2', fontsize=11)\n",
    "            ax.set_title(\n",
    "                f'{model_size} Model - Original Factors\\n({embedding_dim}D → 2D)',\n",
    "                fontsize=14,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.legend(loc='best', fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            filename = f\"qwen3_tsne_original_{model_size}_{timestamp}.png\"\n",
    "            filepath = os.path.join(plots_dir, filename)\n",
    "            plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"  ✓ {filepath}\")\n",
    "            \n",
    "            # Individual plot 2: EFA Factors\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "            \n",
    "            factor_items = factor_assignments[model_size]\n",
    "            n_factors = len(factor_items)\n",
    "            factor_colors_map = plt.cm.get_cmap('tab10', n_factors)\n",
    "            factor_names = sorted(factor_items.keys())\n",
    "            factor_to_color = {comp: factor_colors_map(i) for i, comp in enumerate(factor_names)}\n",
    "            \n",
    "            for factor_name in factor_names:\n",
    "                # Get display name (LLM-generated or default)\n",
    "                if 'factor_name_mappings' in dir() and model_size in factor_name_mappings:\n",
    "                    display_name = factor_name_mappings[model_size].get(factor_name, factor_name)\n",
    "                else:\n",
    "                    display_name = factor_name\n",
    "\n",
    "                indices = [item['index'] for item in factor_items[factor_name]]\n",
    "                if len(indices) > 0:\n",
    "                    ax.scatter(\n",
    "                        embeddings_2d[indices, 0],\n",
    "                        embeddings_2d[indices, 1],\n",
    "                        c=[factor_to_color[factor_name]],\n",
    "                        label=display_name,\n",
    "                        alpha=0.6,\n",
    "                        s=80,\n",
    "                        edgecolors='white',\n",
    "                        linewidth=0.5\n",
    "                    )\n",
    "            \n",
    "            for i in range(len(embeddings_2d)):\n",
    "                ax.annotate(\n",
    "                    codes[i],\n",
    "                    (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                    fontsize=7,\n",
    "                    alpha=0.7,\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords='offset points'\n",
    "                )\n",
    "            \n",
    "            ax.set_xlabel('T-SNE Component 1', fontsize=11)\n",
    "            ax.set_ylabel('T-SNE Component 2', fontsize=11)\n",
    "            ax.set_title(\n",
    "                f'{model_size} Model - EFA Factors\\n({embedding_dim}D → 2D)',\n",
    "                fontsize=14,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.legend(loc='best', fontsize=10)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            filename = f\"qwen3_tsne_efa_{model_size}_{timestamp}.png\"\n",
    "            filepath = os.path.join(plots_dir, filename)\n",
    "            plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"  ✓ {filepath}\")\n",
    "    \n",
    "    print(\"\\n✓ Visualization complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
