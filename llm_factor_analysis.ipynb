{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Factor Analysis - Personality Items\n",
    "\n",
    "Extracts embeddings from NEO personality items using DistilBERT and compares predicted similarities with observed correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LLM Factor Analysis...\n",
      "Data files found. Loading dependencies (this may take a moment)...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"Starting LLM Factor Analysis...\")\n",
    "\n",
    "# Check for required data files\n",
    "required_files = ['NEO_items.csv', 'item_corrs.csv']\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print(f\"Error: Missing required data files: {', '.join(missing_files)}\")\n",
    "    print(\"Please ensure these files are in the current working directory.\")\n",
    "else:\n",
    "    print(\"Data files found. Loading dependencies (this may take a moment)...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - pandas and numpy loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devon7y/VS Code/LLM Factor Analysis/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - datasets loaded\n",
      "  - transformers loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(\"  - pandas and numpy loaded\")\n",
    "\n",
    "from datasets import Dataset\n",
    "print(\"  - datasets loaded\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "print(\"  - transformers loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NEO personality items...\n",
      "Loaded 300 items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go straight for the goal.</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plunge into tasks with all my heart.</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demand quality.</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Set high standards for myself and others.</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turn plans into actions.</td>\n",
       "      <td>Conscientiousness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        item             factor\n",
       "0                  Go straight for the goal.  Conscientiousness\n",
       "1       Plunge into tasks with all my heart.  Conscientiousness\n",
       "2                            Demand quality.  Conscientiousness\n",
       "3  Set high standards for myself and others.  Conscientiousness\n",
       "4                   Turn plans into actions.  Conscientiousness"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading NEO personality items...\")\n",
    "neo_items = pd.read_csv('NEO_items.csv', usecols=['item', 'factor'])\n",
    "print(f\"Loaded {len(neo_items)} items\")\n",
    "\n",
    "# Preview the data\n",
    "neo_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['item', 'factor'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting into a HuggingFace dataset\n",
    "dat = Dataset.from_pandas(neo_items)\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Vocabulary size: 30522, max context length: 512\n"
     ]
    }
   ],
   "source": [
    "# Loading the tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "model_ckpt = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "print(f'Vocabulary size: {tokenizer.vocab_size}, max context length: {tokenizer.model_max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 4719.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenization: ['[CLS]', 'go', 'straight', 'for', 'the', 'goal', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the text\n",
    "print(\"Tokenizing items...\")\n",
    "batch_tokenizer = lambda x: tokenizer(x['item'], padding=True, truncation=True)\n",
    "dat = dat.map(batch_tokenizer, batched=True, batch_size=None)\n",
    "print(f\"Sample tokenization: {[tokenizer.decode(id) for id in dat['input_ids'][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (300, 16)\n"
     ]
    }
   ],
   "source": [
    "# Setting the format of the dataset to torch tensors for passing to the model\n",
    "dat.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
    "print(f\"Dataset shape: {np.array(dat['input_ids']).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyTorch (this may take 10-30 seconds on first run)...\n",
      "  - torch loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading PyTorch (this may take 10-30 seconds on first run)...\")\n",
    "import torch\n",
    "print(\"  - torch loaded\")\n",
    "\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting available device...\n",
      "Using Apple MPS GPU\n"
     ]
    }
   ],
   "source": [
    "# Loading the model and moving it to the GPU if available\n",
    "print(\"Detecting available device...\")\n",
    "if torch.cuda.is_available():  # for nvidia GPUs\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "elif torch.backends.mps.is_available(): # for Apple Metal Performance Shaders (MPS) GPUs\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple MPS GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DistilBERT model...\n",
      "Model inputs: ['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "print(\"Loading DistilBERT model...\")\n",
    "model = AutoModel.from_pretrained('distilbert-base-uncased').to(device)\n",
    "print(f'Model inputs: {tokenizer.model_input_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(batch):\n",
    "    \"\"\"Extract features from a batch of items\"\"\"\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "        return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from items...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 507.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. Shape: (300, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from items...\")\n",
    "dat = dat.map(extract_features, batched=True, batch_size=8)\n",
    "print(f\"Feature extraction complete. Shape: {np.array(dat['hidden_state']).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['item', 'factor', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the dataset structure\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item', 'factor', 'input_ids', 'attention_mask', 'hidden_state']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column names\n",
    "dat.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state shape: torch.Size([768])\n",
      "Embedding size: 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Check embedding dimensions (fast)\n",
    "print(f\"Hidden state shape: {dat[0]['hidden_state'].shape}\")\n",
    "print(f\"Embedding size: {len(dat[0]['hidden_state'])} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 values of first embedding:\n",
      "tensor([-0.1016, -0.2323,  0.0532, -0.2092, -0.1470, -0.4463,  0.1998,  0.2810,\n",
      "         0.1252, -0.6137])\n",
      "\n",
      "Embedding stats:\n",
      "  Min: -7.5746\n",
      "  Max: 3.6303\n",
      "  Mean: -0.0092\n"
     ]
    }
   ],
   "source": [
    "# View a single embedding vector (first 10 values only)\n",
    "print(\"First 10 values of first embedding:\")\n",
    "print(dat[0]['hidden_state'][:10])\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nEmbedding stats:\")\n",
    "print(f\"  Min: {dat[0]['hidden_state'].min():.4f}\")\n",
    "print(f\"  Max: {dat[0]['hidden_state'].max():.4f}\")\n",
    "print(f\"  Mean: {dat[0]['hidden_state'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE Visualization\n",
    "\n",
    "Visualize the 768-dimensional embeddings in 2D space using T-SNE, color-coded by personality construct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "print(\"Visualization libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for T-SNE\n",
    "print(\"Preparing embeddings matrix...\")\n",
    "\n",
    "# Extract all embeddings into a numpy array (300 x 768)\n",
    "embeddings = np.array([dat[i]['hidden_state'] for i in range(len(dat))])\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Reset format to access text columns\n",
    "dat.reset_format()\n",
    "\n",
    "# Extract factor labels from the dataset\n",
    "factors_list = [dat[i]['factor'] for i in range(len(dat))]\n",
    "print(f\"Number of items: {len(factors_list)}\")\n",
    "\n",
    "# Get unique factors for legend\n",
    "unique_factors = sorted(set(factors_list))\n",
    "print(f\"Personality factors: {unique_factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run T-SNE dimensionality reduction\n",
    "print(\"Running T-SNE (this may take 10-30 seconds)...\")\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,      # Reduce to 2D\n",
    "    perplexity=30,       # Balance local vs global structure\n",
    "    max_iter=1000,       # Number of iterations (was n_iter, but sklearn uses max_iter)\n",
    "    random_state=42,     # For reproducibility\n",
    "    verbose=1            # Show progress\n",
    ")\n",
    "\n",
    "# Transform 768D embeddings to 2D\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "print(f\"T-SNE complete! 2D embeddings shape: {embeddings_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Create the T-SNE scatter plot\nprint(\"Creating visualization...\")\n\n# Create a color map for the personality factors\nimport matplotlib.cm as cm\ncolors = cm.get_cmap('tab10', len(unique_factors))\nfactor_to_color = {factor: colors(i) for i, factor in enumerate(unique_factors)}\n\n# Create figure\nplt.figure(figsize=(12, 10))\n\n# Plot each factor with a different color\nfor factor in unique_factors:\n    # Get indices for this factor\n    indices = [i for i, f in enumerate(factors_list) if f == factor]\n    \n    # Plot points for this factor\n    plt.scatter(\n        embeddings_2d[indices, 0],\n        embeddings_2d[indices, 1],\n        c=[factor_to_color[factor]],\n        label=factor,\n        alpha=0.6,\n        s=50\n    )\n\nplt.xlabel('T-SNE Component 1', fontsize=12)\nplt.ylabel('T-SNE Component 2', fontsize=12)\nplt.title('T-SNE Visualization of NEO Personality Item Embeddings\\n(DistilBERT, 300 items)', fontsize=14)\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"Visualization complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Explore nearest neighbors in 2D space\n",
    "print(\"Finding nearest neighbors in embedding space...\")\n",
    "\n",
    "# Pick a random item to analyze\n",
    "sample_idx = 0\n",
    "sample_item = dat[sample_idx]['item']\n",
    "sample_factor = factors_list[sample_idx]\n",
    "\n",
    "print(f\"\\nSample item #{sample_idx}:\")\n",
    "print(f\"  Factor: {sample_factor}\")\n",
    "print(f\"  Text: {sample_item}\")\n",
    "\n",
    "# Calculate distances to all other items in 2D space\n",
    "from scipy.spatial.distance import cdist\n",
    "distances = cdist([embeddings_2d[sample_idx]], embeddings_2d)[0]\n",
    "\n",
    "# Find 5 nearest neighbors (excluding itself)\n",
    "nearest_indices = np.argsort(distances)[1:6]\n",
    "\n",
    "print(f\"\\n5 Nearest neighbors in 2D space:\")\n",
    "for rank, idx in enumerate(nearest_indices, 1):\n",
    "    print(f\"  {rank}. [{factors_list[idx]}] {dat[idx]['item']} (distance: {distances[idx]:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}